Scala
Scala

spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 --jars=gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar

import spark.implicits._

import org.apache.spark.sql.types._

import org.apache.spark.sql.functions

import java.sql.Timestamp

import org.apache.spark.sql.streaming.Trigger.ProcessingTime

val bucket = "apiproject1"

spark.conf.set("temporaryGcsBucket", bucket)

spark.conf.set("parentProject", "big-calling-377519")

val kafkaDF = spark.readStream.format("kafka").option("kafka.bootstrap.servers"," 34.125.126.186:9092").option("subscribe","ornek").load

val schema = StructType(List( StructField("date", DateType, nullable = false), StructField("base", StringType, nullable = false), StructField("name", StringType, nullable = false), StructField("symbols", FloatType, nullable = false), StructField("USD", IntegerType, nullable = false)))


val activationDF = kafkaDF.select(from_json($"value".cast("string"), schema).alias("activation"))

val df = activationDF.select($"activation"("date").alias("date"),

$"activation"("base").alias("base"),

$"activation"("name").alias("name"),
$"activation"("symbols").alias("symbols"),

$"activation"("USD").alias("USD"))



val modelCountQuery=df.writeStream.outputMode("append").format("bigquery").option("table","proje.apiproje").option("checkpointLocation","/path/to/checkpoint/dir/in/hdfs").option("credentialsFile","/home/ozthings_info/big.json").option("failOnDataLoss",false).option("truncate",false).start().awaitTermination()
